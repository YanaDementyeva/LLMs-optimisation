{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "cellId": "fwz0p0wgo3hp2m4w2rdhgr",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:42:12.935106Z",
     "iopub.status.busy": "2024-02-27T16:42:12.934031Z",
     "iopub.status.idle": "2024-02-27T16:42:12.952908Z",
     "shell.execute_reply": "2024-02-27T16:42:12.952152Z",
     "shell.execute_reply.started": "2024-02-27T16:42:12.935059Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List, Union, Tuple, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "810oar01eetq73j1gal2mj",
    "execution_id": "203a1ce4-4e3d-4fc1-921a-3e24f4bfe287"
   },
   "source": [
    "### Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "cellId": "8e4a8s2zovawkd4fe5iodj",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:42:14.730840Z",
     "iopub.status.busy": "2024-02-27T16:42:14.730283Z",
     "iopub.status.idle": "2024-02-27T16:42:14.750277Z",
     "shell.execute_reply": "2024-02-27T16:42:14.749317Z",
     "shell.execute_reply.started": "2024-02-27T16:42:14.730802Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "cellId": "fvtql1xmt1uoawjrvfsmse"
   },
   "outputs": [],
   "source": [
    "zip_f = 'Articles_dataset_rus.zip'\n",
    "z = zipfile.ZipFile(zip_f, 'r')\n",
    "z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "cellId": "767k70bbehp8xf701c7vtj",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:42:15.864049Z",
     "iopub.status.busy": "2024-02-27T16:42:15.863148Z",
     "iopub.status.idle": "2024-02-27T16:42:17.532287Z",
     "shell.execute_reply": "2024-02-27T16:42:17.531447Z",
     "shell.execute_reply.started": "2024-02-27T16:42:15.864001Z"
    },
    "id": "cVW-KOS7qFra",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    puncts = {'(', ')', ':', ';', ',', '.', '\"', '»', '«', '[', ']', '{', '}', '%'}\n",
    "\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    validated_tokens = []\n",
    "    for token in tokens:\n",
    "        is_all_puncts = True\n",
    "        for char in token:\n",
    "            if char not in puncts:\n",
    "                is_all_puncts = False\n",
    "        if is_all_puncts:\n",
    "            validated_tokens.extend(list(token))\n",
    "        else:\n",
    "            validated_tokens.append(token)\n",
    "    return validated_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellId": "g26ni9jz7kfrc61pi4fp2o",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:42:18.906794Z",
     "iopub.status.busy": "2024-02-27T16:42:18.905889Z",
     "iopub.status.idle": "2024-02-27T16:42:18.931759Z",
     "shell.execute_reply": "2024-02-27T16:42:18.930943Z",
     "shell.execute_reply.started": "2024-02-27T16:42:18.906751Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = 'Отсутствие соответствующих задатков не позволяет подготовить высококвалифицированного специалиста и обеспечить эффективность менеджмента.'\n",
    "print(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "cellId": "svrpp22lf8oa2dxj1ioje",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:42:20.665159Z",
     "iopub.status.busy": "2024-02-27T16:42:20.664156Z",
     "iopub.status.idle": "2024-02-27T16:42:20.694680Z",
     "shell.execute_reply": "2024-02-27T16:42:20.693913Z",
     "shell.execute_reply.started": "2024-02-27T16:42:20.665111Z"
    },
    "id": "LMmpCF8J159N",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "cellId": "13uzz1irzhbim5svsak209",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:42:21.604505Z",
     "iopub.status.busy": "2024-02-27T16:42:21.603715Z",
     "iopub.status.idle": "2024-02-27T16:42:21.625833Z",
     "shell.execute_reply": "2024-02-27T16:42:21.625116Z",
     "shell.execute_reply.started": "2024-02-27T16:42:21.604464Z"
    }
   },
   "outputs": [],
   "source": [
    "def txt2csv(path):\n",
    "        for fdir in tqdm(os.listdir(path), desc='converting dataset'):\n",
    "            for file in os.listdir(os.path.join(path, fdir)):\n",
    "                # Цикл для токенизиции и перевода текстовых файлов с аннотациями в .csv\n",
    "                if file == 'text.txt':\n",
    "                    filename = os.path.join(path, fdir, file)\n",
    "                    data = pd.DataFrame(columns=['id', 'token', 'tag'], dtype=object)\n",
    "                    with open(filename, 'r', encoding='utf-8') as f:\n",
    "                        text = ''\n",
    "                        for line in f.readlines():\n",
    "                            text += line\n",
    "                        tokenized_text = tokenize(text)\n",
    "                        for id, token in enumerate(tokenized_text):\n",
    "                            data = pd.concat([data, pd.Series({'id': id, 'token': token}).to_frame().T], ignore_index=True, axis=0, sort=False)\n",
    "                    data.to_csv(filename[:-4] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "cellId": "urrki6ak5pput5h1yetk4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "converting dataset: 100%|██████████| 311/311 [29:44<00:00,  5.74s/it]\n"
     ]
    }
   ],
   "source": [
    "path =  'Articles_dataset_rus'\n",
    "txt2csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "cellId": "el8x92v1cieuhtuarlhtxk"
   },
   "outputs": [],
   "source": [
    "def clear_files(path, rub_filename):\n",
    "        for fdir in tqdm(os.listdir(path), desc='clearing dataset from unnessesary files: '):\n",
    "            for file in os.listdir(os.path.join(path, fdir)):\n",
    "                if file == rub_filename:\n",
    "                    os.remove(os.path.join(path, fdir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "cellId": "vhdbb2kfppxvykppgfopo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "clearing dataset from unnessesary files: 100%|██████████| 311/311 [00:31<00:00,  9.77it/s]\n"
     ]
    }
   ],
   "source": [
    "path =  'Articles_dataset_rus'\n",
    "clear_files(path, 'abstract_labeled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "80e22wvvn1s0419eky3e14p",
    "execution_id": "ad139b8e-e5e2-4f1d-8335-23247f05863b"
   },
   "source": [
    "### Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "cellId": "dnlvrmnqzhb6o9fp6dn51v",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:42:30.885413Z",
     "iopub.status.busy": "2024-02-27T16:42:30.884532Z",
     "iopub.status.idle": "2024-02-27T16:42:31.045450Z",
     "shell.execute_reply": "2024-02-27T16:42:31.044445Z",
     "shell.execute_reply.started": "2024-02-27T16:42:30.885377Z"
    },
    "id": "D4M5UAu6pWNH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Union, Tuple, Any, Set\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "cellId": "sceqo19t88ok82kiw4mud",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:42:31.676661Z",
     "iopub.status.busy": "2024-02-27T16:42:31.675588Z",
     "iopub.status.idle": "2024-02-27T16:42:31.710723Z",
     "shell.execute_reply": "2024-02-27T16:42:31.709813Z",
     "shell.execute_reply.started": "2024-02-27T16:42:31.676607Z"
    },
    "id": "-3FOsYc2qRNf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseExtractor:\n",
    "\n",
    "    def extract(self, text: str) -> List[Tuple[str, str]]:\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "cellId": "qs9d84dg0vb05wn9hldg",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:42:32.461868Z",
     "iopub.status.busy": "2024-02-27T16:42:32.460962Z",
     "iopub.status.idle": "2024-02-27T16:42:32.484122Z",
     "shell.execute_reply": "2024-02-27T16:42:32.483326Z",
     "shell.execute_reply.started": "2024-02-27T16:42:32.461822Z"
    },
    "id": "RQPREaXJp8Z9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_sequence(seq: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "    \"\"\" Валидация последовательности тэгов: убеждаемся, что первый токен каждого термина имеет тэг \"B-TERM\"\n",
    "\n",
    "    :param seq: входная последовательность\n",
    "    :return: провалидированная последовательность\n",
    "    \"\"\"\n",
    "    is_previous_token = False\n",
    "    validated_seq = []\n",
    "    for token, tag in seq:\n",
    "        if tag == Tags.I_TERM.value:\n",
    "            if not is_previous_token:\n",
    "                validated_seq.append((token, Tags.B_TERM.value))\n",
    "            else:\n",
    "                validated_seq.append((token, tag))\n",
    "            is_previous_token = True\n",
    "        elif tag == Tags.B_TERM.value:\n",
    "            validated_seq.append((token, tag))\n",
    "            is_previous_token = True\n",
    "        else:\n",
    "            validated_seq.append((token, tag))\n",
    "            is_previous_token = False\n",
    "    return validated_seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ihw68uz8vvpvewihk8ihy",
    "id": "O7T06d9FcdUz"
   },
   "source": [
    "### get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "cellId": "qwbqt2yd41ekeambtggks",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T16:42:33.615892Z",
     "iopub.status.busy": "2024-02-27T16:42:33.615174Z",
     "iopub.status.idle": "2024-02-27T16:42:37.706258Z",
     "shell.execute_reply": "2024-02-27T16:42:37.705226Z",
     "shell.execute_reply.started": "2024-02-27T16:42:33.615848Z"
    },
    "id": "ZAxRrozYr7oB",
    "outputId": "5c70e0ec-0f32-4529-fded-db99fd73a1fb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.14.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.50.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.2.1)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.10.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.4.2)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.22.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.19.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.3.1)\r\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.46)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2021.11.10)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /kernel/lib/python3.8/site-packages (from transformers) (23.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /kernel/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.9.0)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /kernel/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\r\n",
      "Collecting idna<2.9,>=2.5\r\n",
      "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\r\n",
      "\r",
      "     |████████████████████████████████| 58 kB 1.4 MB/s             \r\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.8/site-packages (from requests->transformers) (2023.11.17)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (8.0.3)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.1.0)\r\n",
      "Requirement already satisfied: six in /kernel/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\r\n",
      "Installing collected packages: idna\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "kaggle 1.5.8 requires urllib3<1.25,>=1.21.1, but you have urllib3 1.25.11 which is incompatible.\r\n",
      "aiohttp 3.8.1 requires charset-normalizer<3.0,>=2.0, but you have charset-normalizer 3.3.2 which is incompatible.\u001b[0m\r\n",
      "Successfully installed idna-2.8\r\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 24.0 is available.\r\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "cellId": "wrf5qy4lq3fqro2uaub5",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:42:37.709249Z",
     "iopub.status.busy": "2024-02-27T16:42:37.708098Z",
     "iopub.status.idle": "2024-02-27T16:43:04.299173Z",
     "shell.execute_reply": "2024-02-27T16:43:04.298441Z",
     "shell.execute_reply.started": "2024-02-27T16:42:37.709205Z"
    },
    "id": "FxM7pN7gr2ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense\n",
    "from transformers import TFBertModel, BertConfig, TFBertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "cellId": "tcwad4qwn9o6qsjlz2c24q",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:43:04.302065Z",
     "iopub.status.busy": "2024-02-27T16:43:04.301173Z",
     "iopub.status.idle": "2024-02-27T16:43:04.320262Z",
     "shell.execute_reply": "2024-02-27T16:43:04.319590Z",
     "shell.execute_reply.started": "2024-02-27T16:43:04.302027Z"
    },
    "id": "t1qHzCMTqnRO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    config = BertConfig.from_pretrained('rubert-base-cased', from_pt = True, num_labels=3)  \n",
    "    model = TFBertForTokenClassification.from_pretrained(\n",
    "            'DeepPavlov/rubert-base-cased',\n",
    "            config=config,\n",
    "            from_pt = True\n",
    "    )\n",
    "    model.layers[-1].activation = tf.keras.activations.softmax\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "cellId": "l20wahdrgbauay708ueb5",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:43:04.322273Z",
     "iopub.status.busy": "2024-02-27T16:43:04.321726Z",
     "iopub.status.idle": "2024-02-27T16:43:04.339316Z",
     "shell.execute_reply": "2024-02-27T16:43:04.338511Z",
     "shell.execute_reply.started": "2024-02-27T16:43:04.322235Z"
    },
    "id": "Jabg8kB9di3P",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Tags(Enum):\n",
    "    B_TERM = 'B-TERM'\n",
    "    I_TERM = 'I-TERM'\n",
    "    NOT_TERM = 'O'\n",
    "\n",
    "\n",
    "TERM_SET = {Tags.B_TERM.value, Tags.I_TERM.value}\n",
    "\n",
    "label2class = {\n",
    "            Tags.NOT_TERM.value: 0,\n",
    "            Tags.B_TERM.value: 1,\n",
    "            Tags.I_TERM.value: 2\n",
    "        }\n",
    "\n",
    "class2label = {\n",
    "            0: Tags.NOT_TERM.value,\n",
    "            1: Tags.B_TERM.value,\n",
    "            2: Tags.I_TERM.value\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "cellId": "ks90ebcsynipis2ag6byjo",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:43:04.341189Z",
     "iopub.status.busy": "2024-02-27T16:43:04.340475Z",
     "iopub.status.idle": "2024-02-27T16:43:04.366033Z",
     "shell.execute_reply": "2024-02-27T16:43:04.365300Z",
     "shell.execute_reply.started": "2024-02-27T16:43:04.341154Z"
    },
    "id": "tgMYA_XtsLm9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "class Vectorizer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\",\n",
    "                                                        do_lower_case=False)\n",
    "\n",
    "        self._label2class = label2class\n",
    "        self._max_length = 134\n",
    "\n",
    "    def vectorize(self, text: List[str], token_labels: List[str]) -> Tuple[List[str], List[int], List[int], List[int]]:\n",
    "        tokenized_text, input_masks, labels = self._tokenize(text, token_labels)\n",
    "\n",
    "        input_ids = self._tokenizer.convert_tokens_to_ids(tokenized_text) # Преобразует последовательность токенов в последовательность идентификаторов, используя словарь.\n",
    "\n",
    "        tags = []\n",
    "        for label in labels:\n",
    "            tags.append(self._label2class[label])\n",
    "\n",
    "        input_ids = self._pad(input_ids)\n",
    "        input_masks = self._pad(input_masks)\n",
    "        tags = self._pad(tags)\n",
    "\n",
    "        return tokenized_text, input_ids, input_masks, tags\n",
    "\n",
    "    def _pad(self, input: List[Any]) -> List[Any]:\n",
    "        if len(input) >= self._max_length:\n",
    "            print(f'Here was a token of length {len(input)}')\n",
    "            return input[:self._max_length]\n",
    "        while len(input) < self._max_length:\n",
    "            input.append(0)\n",
    "        return input\n",
    "\n",
    "    def _tokenize(self, text: List[str], token_labels: List[str]) -> Tuple[List[str], List[int], List[str]]:\n",
    "        tokenized_text = []\n",
    "        labels = []\n",
    "\n",
    "        for token, label in zip(text, token_labels):\n",
    "            # Tokenize the word and count # of subwords the word is broken into\n",
    "            tokenized_word = self._tokenizer.tokenize(token)\n",
    "            n_subwords = len(tokenized_word)\n",
    "\n",
    "            # Add the tokenized word to the final tokenized word list\n",
    "            tokenized_text.extend(tokenized_word)\n",
    "\n",
    "            # Add the same label to the new list of labels `n_subwords` times\n",
    "            labels.extend([label] * n_subwords)\n",
    "\n",
    "        try:\n",
    "\n",
    "            inputs = self._tokenizer.encode_plus(\n",
    "                tokenized_text,\n",
    "                is_pretokenized=True,\n",
    "                return_attention_mask=True,\n",
    "                max_length=self._max_length,\n",
    "                truncation=True\n",
    "            )\n",
    "\n",
    "        except:\n",
    "            print(text)\n",
    "            inputs = dict()\n",
    "            inputs['attention_mask'] = np.zeros(self._max_length)\n",
    "\n",
    "        return tokenized_text, inputs['attention_mask'], labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "k1qxxj7frkrd2lf5utc9no",
    "id": "6TKkn7X5snzQ"
   },
   "source": [
    "### Heuristic validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "cellId": "kxfgd41xx3do2uf1pckj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T16:43:04.367623Z",
     "iopub.status.busy": "2024-02-27T16:43:04.367168Z",
     "iopub.status.idle": "2024-02-27T16:43:06.735398Z",
     "shell.execute_reply": "2024-02-27T16:43:06.734501Z",
     "shell.execute_reply.started": "2024-02-27T16:43:04.367586Z"
    },
    "id": "lB2cum1_s9f4",
    "outputId": "d87edd35-b7e0-4c9b-a91b-debbad74fd41",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.8/dist-packages (0.9.1)\r\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (0.6.2)\r\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (0.7.2)\r\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (2.4.417127.4579844)\r\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 24.0 is available.\r\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "%pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "cellId": "gmnt6lfzxodjvwue15je5o",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:43:06.737361Z",
     "iopub.status.busy": "2024-02-27T16:43:06.736770Z",
     "iopub.status.idle": "2024-02-27T16:43:06.861366Z",
     "shell.execute_reply": "2024-02-27T16:43:06.860583Z",
     "shell.execute_reply.started": "2024-02-27T16:43:06.737317Z"
    },
    "id": "LB6sfi78s6Sq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from pymorphy2.analyzer import Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "cellId": "02r3mc2b0p84k42ym3kplx",
    "execution": {
     "iopub.execute_input": "2024-02-27T16:43:06.865469Z",
     "iopub.status.busy": "2024-02-27T16:43:06.864149Z",
     "iopub.status.idle": "2024-02-27T16:43:07.082071Z",
     "shell.execute_reply": "2024-02-27T16:43:07.081346Z",
     "shell.execute_reply.started": "2024-02-27T16:43:06.865424Z"
    },
    "id": "yHza_k7hstAH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ADJF = 'ADJF'\n",
    "CONJ = 'CONJ'\n",
    "GRND = 'GRND'\n",
    "NOUN = 'NOUN'\n",
    "PREP = 'PREP'\n",
    "PRTF = 'PRTF'\n",
    "PRTS = 'PRTS'\n",
    "VERB = 'VERB'\n",
    "\n",
    "GENT = 'gent'\n",
    "\n",
    "\n",
    "class HeuristicValidator:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    def validate(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        result = self._heuristic_1(result)\n",
    "        result = self._heuristic_2(result)\n",
    "        result = self._heuristic_3(result)\n",
    "        result = self._heuristic_4(result)\n",
    "        result = self._heuristic_5(result)\n",
    "        result = self._heuristic_6(result)\n",
    "        result = self._heuristic_7(result)\n",
    "        # result = self._heuristic_8(result)\n",
    "        result = self._heuristic_9(result)\n",
    "        result = self._heuristic_10(result)\n",
    "        return result\n",
    "\n",
    "    def _heuristic_1(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Валидация цепочек, которые представляют собой СУЩ + СУЩ в род.п., например: методы сжатия данных\"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "        updated_tokens = set()\n",
    "\n",
    "        for i, (result_pair_1, result_pair_2) in enumerate(zip(result, result[1:])):\n",
    "            id_1 = i\n",
    "            id_2 = i + 1\n",
    "            # если последовательность не содержит терминов, то пропускаем\n",
    "            if result_pair_1[1] == Tags.NOT_TERM.value and result_pair_2[1] == Tags.NOT_TERM.value:\n",
    "                continue\n",
    "            token_1, token_2 = result_pair_1[0], result_pair_2[0]\n",
    "            pos_1 = self._morph.parse(token_1)[0].tag.POS\n",
    "            case_2 = self._morph.parse(token_2)[0].tag.case\n",
    "            if pos_1 in [NOUN, ADJF] and case_2 == GENT:\n",
    "                if result_pair_1[1] not in TERM_SET and id_1 not in updated_tokens:\n",
    "                    result_pair_1 = (token_1, Tags.B_TERM.value)\n",
    "                    updated_result[id_1] = result_pair_1\n",
    "                    updated_tokens.add(id_1)\n",
    "                result_pair_2 = (token_2, Tags.I_TERM.value)\n",
    "                updated_result[id_2] = result_pair_2\n",
    "                updated_tokens.add(id_2)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_2(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        Если токены представляют собой последовательность ПРИЛ + СУЩ и оба помечены B-TERM, то приводим к\n",
    "        последовательности B-TERM I-TERM\n",
    "        \"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, (result_pair_1, result_pair_2) in enumerate(zip(result, result[1:])):\n",
    "            id_1 = i\n",
    "            id_2 = id_1 + 1\n",
    "            # если последовательность не содержит терминов, то пропускаем\n",
    "            if result_pair_1[1] == Tags.B_TERM.value and result_pair_2[1] == Tags.B_TERM.value:\n",
    "                token_1, token_2 = result_pair_1[0], result_pair_2[0]\n",
    "                parse_1 = self._morph.parse(token_1)\n",
    "                parse_2 = self._morph.parse(token_2)\n",
    "                is_adj_1 = self.__check_pos(ADJF, parse_1)\n",
    "                is_noun_2 = self.__check_pos(NOUN, parse_2)\n",
    "                if is_adj_1 and is_noun_2:\n",
    "                    updated_result[id_1] = (token_1, Tags.B_TERM.value)\n",
    "                    updated_result[id_2] = (token_2, Tags.I_TERM.value)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_3(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Удаление тэга B-TERM или I-TERM, если он был присовен токену знака пунктуации \"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, result_pair in enumerate(result):\n",
    "            if result_pair[0] in ['.', ',', ':', ';'] and result_pair[1] in [Tags.B_TERM.value, Tags.I_TERM.value]:\n",
    "                updated_result[i] = (result_pair[0], Tags.NOT_TERM.value)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_4(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Если последний токен в термине имеет часть речи ПРИЛ, а следующий токен - СУЩ, но либо не входит в термин,\n",
    "        либо имеет тэг \"B-TERM\", то второй токен включаем в состав термина\n",
    "        \"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, (result_pair_1, result_pair_2) in enumerate(zip(result, result[1:])):\n",
    "            id_1 = i\n",
    "            id_2 = id_1 + 1\n",
    "            if result_pair_1[1] in TERM_SET and result_pair_2[1] != Tags.I_TERM.value:\n",
    "                token_1, token_2 = result_pair_1[0], result_pair_2[0]\n",
    "                parse_1 = self._morph.parse(token_1)\n",
    "                parse_2 = self._morph.parse(token_2)\n",
    "                is_adj_1 = self.__check_pos(ADJF, parse_1)\n",
    "                is_prtf_1 = self.__check_pos(PRTF, parse_1)\n",
    "                is_noun_2 = self.__check_pos(NOUN, parse_2)\n",
    "                if is_noun_2:\n",
    "                    if is_adj_1 or is_prtf_1:\n",
    "                        updated_result[id_2] = (token_2, Tags.I_TERM.value)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_5(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Удаление тэга B-TERM у предлога и союза (допускаем, что предлог может входить в состав термина, но не может\n",
    "        начинать его \"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, result_pair in enumerate(result):\n",
    "            if result_pair[1] == Tags.B_TERM.value:\n",
    "                parse = self._morph.parse(result_pair[0])\n",
    "                is_prep = self.__check_pos(PREP, parse)\n",
    "                is_conj = self.__check_pos(CONJ, parse)\n",
    "                if is_prep or is_conj:\n",
    "                    updated_result[i] = (result_pair[0], Tags.NOT_TERM.value)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_6(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Удаление тэга Термин у однозначного глагола или деепричастия \"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, result_pair in enumerate(result):\n",
    "            if result_pair[1] in [Tags.B_TERM.value, Tags.I_TERM.value]:\n",
    "                parse = self._morph.parse(result_pair[0])\n",
    "                is_verb = self.__check_pos(VERB, parse)\n",
    "                is_grnd = self.__check_pos(GRND, parse)\n",
    "                is_prts = self.__check_pos(PRTS, parse)\n",
    "                if len(parse) == 1:\n",
    "                    if is_verb or is_grnd or is_prts:\n",
    "                        updated_result[i] = (result_pair[0], Tags.NOT_TERM.value)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_7(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Если следующий за термином токен состоит только из латинских символов, то включаем его в состав термина \"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, (result_pair_1, result_pair_2) in enumerate(zip(result, result[1:])):\n",
    "            id_1 = i\n",
    "            id_2 = id_1 + 1\n",
    "            if result_pair_1[1] in TERM_SET:\n",
    "                token_2 = result_pair_2[0]\n",
    "                is_latin = self._is_latin(token_2)\n",
    "                if is_latin:\n",
    "                    updated_result[id_2] = (token_2, Tags.I_TERM.value)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_8(self, result: List[Tuple[str, str]]):\n",
    "        \"\"\" Удаление тэга B-TERM у предлога и союза, которые идут после определения\n",
    "        Н/р: ..исследование статистического и динамического провисания ..\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _heuristic_9(self, result: List[Tuple[str, str]]):\n",
    "        \"\"\"Чаще всего, всё, что стоит в кавычках, относится к термину, если он там выделен\n",
    "        Н/р: .. компьютерный инструмент «оптимизация с ограничениями» ..\"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, result_pair in enumerate(result):\n",
    "            if result_pair[0] in ['\"', '«', '“', 'ˮ']:\n",
    "                try:\n",
    "                    if result[i + 1][1] == Tags.B_TERM.value:\n",
    "                        is_fin = False\n",
    "                        k = 2\n",
    "                        while not is_fin:\n",
    "                            next_pair = result[i + k]\n",
    "                            is_fin = next_pair[0] in ['\"', '»', '”', '‟']\n",
    "                            if next_pair[1] not in TERM_SET and not is_fin:\n",
    "                                updated_result[i + k] = (next_pair[0], Tags.I_TERM.value)\n",
    "                            k += 1\n",
    "                except IndexError:  # если кавычки стоят в конце текста\n",
    "                    pass\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_10(self, result: List[Tuple[str, str]]):\n",
    "        \"\"\"Исправление разметки терминов, которые пишутся через дефис.\n",
    "        Иногда часть составного термина при разметке \"теряется\"\n",
    "        Н/р: ... курсов математической физики, физико-математической информатики и дифференциальных уравнений ...\"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, result_pair in enumerate(result):\n",
    "          try:\n",
    "            if result_pair[0] == \"-\" and ((result[i+1][1] in TERM_SET) ^ (result[i-1][1] in TERM_SET)):\n",
    "                if str(result[i-1][0])[-1] in ['о', 'е']:\n",
    "                    if result[i-1][1] not in TERM_SET:\n",
    "                        updated_result[i-1] = (result[i-1][0], Tags.B_TERM.value)\n",
    "                    updated_result[i] = (result[i][0], Tags.I_TERM.value)\n",
    "                    updated_result[i + 1] = (result[i + 1][0], Tags.I_TERM.value)\n",
    "          except IndexError:\n",
    "            pass\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def __check_pos(self, pos: str, parses: List[Parse]) -> bool:\n",
    "            for parse in parses:\n",
    "                if pos in parse.tag:\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "    def _is_latin(self, token: str) -> bool:\n",
    "        latin_symbols = 'qwertyuiopasdfghjklzxcvbnm'\n",
    "        is_latin = True\n",
    "        for char in token.lower():\n",
    "            if char not in latin_symbols:\n",
    "                is_latin = False\n",
    "                return is_latin\n",
    "        return is_latin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3yywpmh1zn71ud5yobgcz8",
    "execution_id": "e9b90a9d-4715-4ea6-865c-9fc7c742a153",
    "id": "nqksozIjtXBm"
   },
   "source": [
    "### DLExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "cellId": "uv7lg2zgigl4cqb963rm5c",
    "execution": {
     "iopub.execute_input": "2024-02-27T18:17:04.766364260Z",
     "iopub.status.busy": "2024-02-27T18:17:39.579606Z",
     "iopub.status.idle": "2024-02-27T18:17:42.884100Z",
     "shell.execute_reply": "2024-02-27T18:17:42.883294Z",
     "shell.execute_reply.started": "2024-02-27T18:17:39.580946Z"
    },
    "id": "koAMWhKJtb-Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DLExtractor(BaseExtractor):\n",
    "    \"\"\" Класс для извлечения терминов из текста с помощью модели \"\"\"\n",
    "\n",
    "    def __init__(self, weights_path):\n",
    "        weights_path = weights_path\n",
    "        self._model = get_model()\n",
    "        self._model.load_weights(weights_path)\n",
    "        self._vectorizer = Vectorizer()\n",
    "        self._heuristic_validator = HeuristicValidator()\n",
    "        self._class2label = class2label\n",
    "\n",
    "    def extract(self, text: Union[str, List[str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Извлечение терминов из входного текста\n",
    "\n",
    "        :param text: входной текст, может быть строкой либо уже токенизированным (тогда списком строк)\n",
    "        :return: Список кортежей, в которых первый элемент - токен, второй элемент - тэг\n",
    "        \"\"\"\n",
    "        if isinstance(text, str): # проверка на то, что далее работаем со списком строк (токенов)\n",
    "            tokens = tokenize(text)\n",
    "        else:\n",
    "            tokens = text\n",
    "\n",
    "        labels = [Tags.NOT_TERM.value for i in range(len(tokens))]\n",
    "\n",
    "        all_bpe_tokens = []\n",
    "        all_predictions = []\n",
    "\n",
    "        # делим список токенов на батчи, которые будут последовательно обрабатываться\n",
    "        n_batches = int(len(tokens) / 50) + 1\n",
    "        for i in range(n_batches):\n",
    "            start = 50 * i\n",
    "            end = min(len(tokens), 50 * i + 50)\n",
    "\n",
    "            if start == end:\n",
    "                break\n",
    "\n",
    "            bpe_tokens, input_ids, input_masks, tags = self._vectorizer.vectorize(\n",
    "                  tokens[start: end], labels[start: end]\n",
    "              )\n",
    "            preds = self._model.predict_on_batch([np.array([input_ids]), np.array([input_masks])])[0][0]\n",
    "            all_bpe_tokens.extend(bpe_tokens)\n",
    "            all_predictions.extend(preds[:len(bpe_tokens)])\n",
    "\n",
    "        result = self._get_preds_with_tokens(all_bpe_tokens, all_predictions)\n",
    "        result = self._heuristic_validator.validate(result)\n",
    "        result = validate_sequence(result)\n",
    "\n",
    "        if isinstance(text, list):\n",
    "            result = self._align_tokens(tokens, result)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _align_tokens(self, input_tokens: List[str], result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Выравнивание токенов\n",
    "        В случаях, когда на вход пришёл уже токенизированный текст, токены в результирующем списке могут отличаться от\n",
    "        тех, что в исходном, из-за bpe-токенизации. Поэтому нужно выровнять результирующий список относительно входного,\n",
    "        т.е. список токенов в обоих списках должен совпадать\n",
    "\n",
    "        :param input_tokens: список токенов во входном списке\n",
    "        :param result: результирующий список кортежей, в которых первый элемент - токен, второй - тэг\n",
    "        :return: список кортежей, в которых первый элемент - токен, второй - тэг\n",
    "        \"\"\"\n",
    "        # если списки токенов изначально совпадают, то сразу возвращаем результат\n",
    "        resulted_tokens = [res[0] for res in result]\n",
    "        if resulted_tokens == input_tokens:\n",
    "            return result\n",
    "\n",
    "        updated_result = []\n",
    "\n",
    "        # фиксируем позицию токена в результирующем списке\n",
    "        res_cursor = 0\n",
    "        for i, token in enumerate(input_tokens):\n",
    "\n",
    "            # токенизируем токен из входного списка. Если длина получившихся токенов == 1, то это не составной токен\n",
    "            tokenized = tokenize(token)\n",
    "            if len(tokenized) == 1: # если bpe-токен воспринимается как одно слово, добавляем его в результирующий список\n",
    "              try:\n",
    "                if token != result[i]:\n",
    "                    updated_result.append((token, Tags.NOT_TERM.value))\n",
    "                    result.insert(i, token)\n",
    "                else:\n",
    "                    updated_result.append(result[i])\n",
    "                res_cursor += 1\n",
    "                continue\n",
    "              except:\n",
    "                print('here:', len(result))\n",
    "                print([res[0] for res in result])\n",
    "                print(input_tokens)\n",
    "\n",
    "            full_resulted = []\n",
    "            tags = Counter()\n",
    "            # собираем все токены в результирующем списке, которые лежат в промежутке от res_cursor до\n",
    "            # res_cursor + количество токенов в tokenized\n",
    "            for j in range(res_cursor, res_cursor + len(tokenized)):\n",
    "                full_resulted.append(result[j][0])\n",
    "                tags[result[j][1]] += 1\n",
    "\n",
    "            # на случай, если составным токенам были присвоены разные тэги, то выберем тэг с максимальной частотой\n",
    "            tag = tags.most_common()[0][0]\n",
    "            updated_result.append((''.join(full_resulted), tag))\n",
    "\n",
    "            # переведём позицию курсора на количество составных частей исходного токена\n",
    "            res_cursor += len(tokenized)\n",
    "\n",
    "        assert len(input_tokens) == len(updated_result), 'Alignment worked incorrect'\n",
    "\n",
    "        return updated_result\n",
    "\n",
    "    def _get_preds_with_tokens(self, bpe_tokens: List[str], preds) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Из предсказаний для bpe-токенов получаем предскания для целых токенов\n",
    "\n",
    "        :param bpe_tokens: список bpe-токенов\n",
    "        :param preds: список предиктов от модели\n",
    "        :return: Список кортежей, в которых первый элемент - полноценный токен, второй элемент - тэг\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        token = []\n",
    "        tags = []\n",
    "\n",
    "        for bpe_token, pred in zip(bpe_tokens, preds):\n",
    "\n",
    "            # если bpe-токен не является началом целого токена, то он начинается с \"##\"\n",
    "            if bpe_token.startswith('##'):\n",
    "                token.append(bpe_token[2:])\n",
    "                tags.append(self._class2label[np.argmax(pred)])\n",
    "\n",
    "            else:\n",
    "                # если уже собрали токен до этого, то обработаем его и положим в результирущий список\n",
    "                if len(token) > 0:\n",
    "                    self._process_token(result, tags, token)\n",
    "\n",
    "                token = [bpe_token]\n",
    "                tags = [self._class2label[np.argmax(pred)]]\n",
    "\n",
    "        # обработаем последний токен и положим его в результирующий список\n",
    "        self._process_token(result, tags, token)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _process_token(self, result: List[Tuple[str, str]], tags: List[str], token: List[str]):\n",
    "        \"\"\"Обработка токена: собираем его из bpe-токенов, выбираем нужный тэг\n",
    "\n",
    "        :param result: результирующий список с токенами и тэгами\n",
    "        :param tags: список тэгов, который был получен для составных bpe-токенов\n",
    "        :param token: список bpe-токенов для данного токена\n",
    "        \"\"\"\n",
    "        # объединяем составные bpe-токены в единую строку\n",
    "        token_str = ''.join(token)\n",
    "\n",
    "        tag = Tags.NOT_TERM.value\n",
    "\n",
    "        # если во входном списке тэгов есть B-TERM или I-TERM, то выбираем данный тэг\n",
    "        if Tags.B_TERM.value in tags:\n",
    "            tag = Tags.B_TERM.value\n",
    "        elif Tags.I_TERM.value in tags:\n",
    "            tag = Tags.I_TERM.value\n",
    "\n",
    "        result.append((token_str, tag))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "w27xx3ncboapvk1hwby6",
    "execution_id": "bb06fd06-cbc6-4112-b2da-2a649ed3ea88",
    "id": "B3H9NHN4Itum"
   },
   "source": [
    "## get new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "cellId": "ffjtft0dd1oklw5o5agt2n",
    "execution": {
     "iopub.execute_input": "2024-02-27T18:17:43.197306617Z",
     "iopub.status.busy": "2024-02-27T18:17:45.666912Z",
     "iopub.status.idle": "2024-02-27T18:17:46.260414Z",
     "shell.execute_reply": "2024-02-27T18:17:46.259692Z",
     "shell.execute_reply.started": "2024-02-27T18:17:45.667948Z"
    },
    "id": "NSXQeLywTFR4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Marker:\n",
    "\n",
    "    def __init__(self, path_to_weights, path_to_files):\n",
    "        self._predictor = DLExtractor(path_to_weights)\n",
    "        self._path_to_files = path_to_files\n",
    "        self._max_len = 128\n",
    "\n",
    "    def mark_dataset(self):\n",
    "        c = 0\n",
    "        dirs = sorted(os.listdir(self._path_to_files))\n",
    "        path = self._path_to_files\n",
    "        for article_dir in tqdm(dirs, desc='loading dataset'):\n",
    "            if 'text.csv' in os.listdir(os.path.join(self._path_to_files, article_dir)):\n",
    "                filename = os.path.join(self._path_to_files, article_dir, 'text.csv')\n",
    "                df = pd.read_csv(filename)\n",
    "                with open(filename, 'r') as f:\n",
    "                    tokens = []\n",
    "                    labels = []\n",
    "                    file_samples = []\n",
    "                    file_labels = []\n",
    "                    reader = csv.DictReader(f)\n",
    "                    for row in reader:\n",
    "                        tokens.append(row['token'])\n",
    "                        if len(tokens) == self._max_len:\n",
    "                            file_samples.append(tokens)\n",
    "                            preds = self._predictor.extract(tokens)\n",
    "                            for (tok, tag) in preds:\n",
    "                                labels.append(tag)\n",
    "                            file_labels.append(labels)\n",
    "                            tokens = []\n",
    "                            labels = []\n",
    "                    if len(tokens) > 0:\n",
    "                        file_samples.append(tokens)\n",
    "                        preds = self._predictor.extract(tokens)\n",
    "                        for (tok, tag) in preds:\n",
    "                            labels.append(tag)\n",
    "                        file_labels.append(labels)\n",
    "                        try:\n",
    "                            df['tag'] = self.flatten_list(file_labels)\n",
    "                        except:\n",
    "                            print(file_labels)\n",
    "                    df.to_csv(filename[:-4]+'_labeled.csv', index=False)\n",
    "                c += 1\n",
    "        if c == len(dirs)-1:\n",
    "            print(f'{c} files marked up!')\n",
    "\n",
    "    def flatten_list(self, lists):\n",
    "      flat_list = []\n",
    "      for l in lists:\n",
    "          if type(l) is list:\n",
    "              for item in l:\n",
    "                  flat_list.append(item)\n",
    "          else:\n",
    "              flat_list.append(l)\n",
    "      return flat_list\n",
    "\n",
    "\n",
    "    def replace_space(self, y):\n",
    "      for elem in y:\n",
    "        if isinstance(elem, str):\n",
    "          for i in range(len(y)):\n",
    "            if y[i] == '':\n",
    "              y[i] = 'O'\n",
    "        elif isinstance(elem, list):\n",
    "          for sample in y:\n",
    "            for i in range(len(sample)):\n",
    "              if sample[i] == '':\n",
    "                sample[i] = 'O'\n",
    "      return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellId": "ncz6p4jpwegcd3gg6xg4aa",
    "execution": {
     "iopub.execute_input": "2024-02-27T15:35:41.026262Z",
     "iopub.status.busy": "2024-02-27T15:35:41.025620Z",
     "iopub.status.idle": "2024-02-27T15:35:41.043877Z",
     "shell.execute_reply": "2024-02-27T15:35:41.043185Z",
     "shell.execute_reply.started": "2024-02-27T15:35:41.026231Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sorted(os.listdir('Articles_dataset_rus'))[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "cellId": "fhf58yfjv4wc7yd6w4i519",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-27T18:17:53.439016875Z",
     "iopub.status.busy": "2024-02-27T18:17:54.468496Z",
     "iopub.status.idle": "2024-02-27T19:34:58.811508Z",
     "shell.execute_reply": "2024-02-27T19:34:58.810262Z",
     "shell.execute_reply.started": "2024-02-27T18:17:54.469266Z"
    },
    "id": "um1KdfVYXuWR",
    "outputId": "7b30592d-3c5f-40f2-df73-ab18d921cfba",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_token_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  177262848 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  2307      \n",
      "=================================================================\n",
      "Total params: 177,265,155\n",
      "Trainable params: 177,265,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "135\n",
      "134\n",
      "135\n",
      "290 files marked up!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 18:18:26.261509: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2024-02-27 18:18:26.261547: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-02-27 18:18:26.261564: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (s-56710586-5f65-4e9f-a5d3-96b58ef35bbb): /proc/driver/nvidia/version does not exist\n",
      "2024-02-27 18:18:26.261812: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForTokenClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\r",
      "loading dataset:   0%|          | 0/291 [00:00<?, ?it/s]2024-02-27 18:20:12.153581: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "\r",
      "loading dataset: 100%|██████████| 291/291 [1:14:52<00:00, 15.44s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    path_to_weights, path_to_files = 'weights/RUbert_cross_domain_main_weights.h5', 'Articles_dataset_rus'\n",
    "    marker = Marker(path_to_weights, path_to_files)\n",
    "    marker.mark_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ucv9e26731r312r0wcagto",
    "execution_id": "6bcfcfcf-21d6-4b7d-9422-9bfb0cce9251"
   },
   "source": [
    "### after we got marked up files, we should collect them into one archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "cellId": "7fqrx1x6q2gk0xjdie8py",
    "execution": {
     "iopub.execute_input": "2024-02-28T05:09:05.117318914Z",
     "iopub.status.busy": "2024-02-28T05:09:06.083573Z",
     "iopub.status.idle": "2024-02-28T05:09:06.109077Z",
     "shell.execute_reply": "2024-02-28T05:09:06.108244Z",
     "shell.execute_reply.started": "2024-02-28T05:09:06.084477Z"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def collect_zip(sourse, target):\n",
    "    zippath = \"texts.zip\"\n",
    "    with zipfile.ZipFile(zippath, \"a\", compression=zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for article_dir in tqdm(sorted(os.listdir(sourse)), desc='collecting data to zip'):\n",
    "          if article_dir.startswith('.'):\n",
    "            continue\n",
    "          if target in os.listdir(os.path.join(sourse, article_dir)):\n",
    "            source_path = os.path.join(sourse, article_dir, target)\n",
    "            arcname = f'{article_dir}.csv'\n",
    "            zipf.write(source_path, arcname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "cellId": "r4ostko119kzq1wb10vu9",
    "execution": {
     "iopub.execute_input": "2024-02-28T05:09:06.784704289Z",
     "iopub.status.busy": "2024-02-28T05:09:07.660383Z",
     "iopub.status.idle": "2024-02-28T05:09:10.616181Z",
     "shell.execute_reply": "2024-02-28T05:09:10.615411Z",
     "shell.execute_reply.started": "2024-02-28T05:09:07.661303Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "collecting data to zip: 100%|██████████| 311/311 [00:02<00:00, 107.35it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = 'Articles_dataset_rus'\n",
    "    target = 'text_labeled.csv'\n",
    "    \n",
    "    collect_zip(path, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "srah7wlnf8e34ibiu1965j"
   },
   "source": [
    "Чтобы дообучить модель YandexGPT, нужно подготовить файл в формате JSON, содержащий примеры как минимум 10 запросов и эталонных ответов в кодировке UTF-8:\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"request\": \"текстовый запрос\",\n",
    "    \"response\": \"ожидаемый ответ\"\n",
    "  },\n",
    "  {\n",
    "    \"request\": \"еще один текстовый запрос\",\n",
    "    \"response\": \"новый ожидаемый ответ\"\n",
    "  },\n",
    "  …\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellId": "jxy34iu5ql7a08jbjtkhg6"
   },
   "outputs": [],
   "source": [
    "def collect_dict(sourse):\n",
    "    dictfile = \"req_res_dict.json\"\n",
    "    with open(dictfile, 'a') as dictf:\n",
    "        for article_dir in tqdm(sorted(os.listdir(sourse)), desc='collecting data to dict'):\n",
    "            if article_dir.startswith('.'):\n",
    "                continue\n",
    "            if 'abstract.txt' in os.listdir(os.path.join(sourse, article_dir)):\n",
    "                source_path = os.path.join(sourse, article_dir, 'abstract.txt')\n",
    "                with open(source_path, 'r', encoding='utf-8') as txtfile:\n",
    "                    text = txtfile.read().replace('\\n', ' ')\n",
    "                request = f'Выдели все научные термины из текста: \"{text}\"'\n",
    "            source_path = os.path.join(sourse, article_dir, 'abstract_labeled.csv')\n",
    "            with open(source_path), 'r') as f:\n",
    "                    tokens = []\n",
    "                    labels = []\n",
    "                    reader = csv.DictReader(f)\n",
    "                    for row in reader:\n",
    "                        \n",
    "                        elif row['tag'] == 'B-TERM':\n",
    "                            term.append(row['token'])\n",
    "                        \n",
    "                            labels.append(row['tag'])                    \n",
    "\n",
    "                \n",
    "                \n",
    "def replace_space(self, y: List[str]):\n",
    "     for elem in y:\n",
    "        if isinstance(elem, str):\n",
    "            for i in range(len(y)):\n",
    "                if y[i] == '':\n",
    "                      y[i] = 'O'\n",
    "        elif isinstance(elem, list):\n",
    "            for sample in y:\n",
    "                for i in range(len(sample)):\n",
    "                    if sample[i] == '':\n",
    "                        sample[i] = 'O'\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellId": "822cxnpanq89i4fcylwam"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-9JaZrB-eVus",
    "W2ngs-mSecGs",
    "O7T06d9FcdUz",
    "vP-vFHbQcgh7",
    "6TKkn7X5snzQ",
    "wQaEs5qTWevC",
    "saOCVa7JVUZ2"
   ],
   "provenance": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "9c84d4ac-74b6-45e8-b691-5d73e72152c5",
  "notebookPath": "get_files.ipynb",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0486752f1c244a8ea1d63730905e6138": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14b28b39580b4ac9908a35a9aa57efec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c03075efd2749d1b70e13bdf4cc1d76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5567e1d25fa4937b2149d3593510c55",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14b28b39580b4ac9908a35a9aa57efec",
      "value": 29
     }
    },
    "23ece7fef01f40dcb4eec2103e899652": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3289058bdf144a23bc29d53f7d56e25d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33756245041e4434a30cb82cd3642bdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a804cbf74bc34cc78696450965971f22",
       "IPY_MODEL_8cf6f946c797446ebeb5387954d07543",
       "IPY_MODEL_44f74acf14454c3da878e1d7a71c5a50"
      ],
      "layout": "IPY_MODEL_91d7725865974b28b496fda4233aad87"
     }
    },
    "35bdb5de9dc04549b4397a5a5ef72c55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39b1bd3ed29e4ddf8b7c29fa00762b4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3a49f0b63b4540aa98fccaf877bfd36f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c995af3ee4f41cabc2641d28ec017e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44f74acf14454c3da878e1d7a71c5a50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_925aaf7d90df43868d8b79221b28efcd",
      "placeholder": "​",
      "style": "IPY_MODEL_69a53c80d3e74b6a9a177310964a85fc",
      "value": " 996k/996k [00:00&lt;00:00, 3.89MB/s]"
     }
    },
    "510b4e1e218444e78947289b0447cc04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b96888e692dd4c4da4d9f0d979a58b83",
      "placeholder": "​",
      "style": "IPY_MODEL_640b2361f5cc4b578a6dfa983c18652c",
      "value": " 29.0/29.0 [00:00&lt;00:00, 625B/s]"
     }
    },
    "5b2a4b36806c4ecfabd2897a1e98d203": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c6080f11d9f4fa58a4ec78dbaaf42a0",
       "IPY_MODEL_99ab0115b4864288b289cb32cd875396",
       "IPY_MODEL_af422d81fbc841d797f6dfb606c79658"
      ],
      "layout": "IPY_MODEL_81621f9cd0754ce185f6904cca0c88ff"
     }
    },
    "5c1f5b6dc5594bb9ad5977adbe6b2533": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "640b2361f5cc4b578a6dfa983c18652c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69a53c80d3e74b6a9a177310964a85fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c6080f11d9f4fa58a4ec78dbaaf42a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a051be2a41974460b9ad233d5418a0d4",
      "placeholder": "​",
      "style": "IPY_MODEL_f5f354a6ac484a31a3b84c64f5b7e878",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "7e10bc0f10eb4f3a9754134c7f2b1cb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81621f9cd0754ce185f6904cca0c88ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cf6f946c797446ebeb5387954d07543": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c1f5b6dc5594bb9ad5977adbe6b2533",
      "max": 995526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_35bdb5de9dc04549b4397a5a5ef72c55",
      "value": 995526
     }
    },
    "91d7725865974b28b496fda4233aad87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "925aaf7d90df43868d8b79221b28efcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99ab0115b4864288b289cb32cd875396": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a54e8fa8f24848dcaef018e4792891af",
      "max": 625,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39b1bd3ed29e4ddf8b7c29fa00762b4f",
      "value": 625
     }
    },
    "a051be2a41974460b9ad233d5418a0d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a105d1b33ab24be8ad18d86a818400b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a54e8fa8f24848dcaef018e4792891af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a804cbf74bc34cc78696450965971f22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3289058bdf144a23bc29d53f7d56e25d",
      "placeholder": "​",
      "style": "IPY_MODEL_7e10bc0f10eb4f3a9754134c7f2b1cb0",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "af422d81fbc841d797f6dfb606c79658": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23ece7fef01f40dcb4eec2103e899652",
      "placeholder": "​",
      "style": "IPY_MODEL_0486752f1c244a8ea1d63730905e6138",
      "value": " 625/625 [00:00&lt;00:00, 22.7kB/s]"
     }
    },
    "b96888e692dd4c4da4d9f0d979a58b83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbba160310854ef0b5ad28b4a96a1c13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c48c6e99c5a8459d9bb94bd0ceec7bba",
       "IPY_MODEL_1c03075efd2749d1b70e13bdf4cc1d76",
       "IPY_MODEL_510b4e1e218444e78947289b0447cc04"
      ],
      "layout": "IPY_MODEL_3a49f0b63b4540aa98fccaf877bfd36f"
     }
    },
    "c48c6e99c5a8459d9bb94bd0ceec7bba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a105d1b33ab24be8ad18d86a818400b2",
      "placeholder": "​",
      "style": "IPY_MODEL_3c995af3ee4f41cabc2641d28ec017e0",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "f5567e1d25fa4937b2149d3593510c55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5f354a6ac484a31a3b84c64f5b7e878": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
