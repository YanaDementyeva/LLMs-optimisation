{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "qwbqt2yd41ekeambtggks",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZAxRrozYr7oB",
    "outputId": "5c70e0ec-0f32-4529-fded-db99fd73a1fb",
    "tags": [
     "prerequizites"
    ]
   },
   "outputs": [],
   "source": [
    "# Before launching - setup new conda enviroment with following:\n",
    "# $> conda create --name mllm -c conda-forge ipykernel ipywidgets tqdm tensorflow\n",
    "# Prerequizites\n",
    "%pip install nltk\n",
    "%pip install pandas\n",
    "%pip install transformers\n",
    "%pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "8e4a8s2zovawkd4fe5iodj",
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "# Stage 0: Dataset loading and preprocessing\n",
    "\n",
    "################################## IMPORTS ###################################\n",
    "# First we import standard lib modules\n",
    "#import os      -  slightly outdated, there is a better way since 3.4\n",
    "from pathlib import Path                    # abstract cross-platform path\n",
    "from shutil import unpack_archive           # high-level shell-functionality\n",
    "import string                               # stdlib string support\n",
    "\n",
    "# Next after blank line - pip/conda packages - not a standard library\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Lastly our own project modules - not very applicable to a single notebook:)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "7abfys4lg974y47ufyswtr",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Stage 0: Dataset loading and preprocessing\n",
    "\n",
    "############################## GLOBAL CONSTANTS ##############################\n",
    "## Paths\n",
    "WORK_DIR_PATH = Path('.')\n",
    "DATASET_ZIP_PATH = WORK_DIR_PATH.joinpath('Articles_dataset_rus.zip')\n",
    "INTERMID_DIR_PATH = WORK_DIR_PATH.joinpath('unzipped-dataset')\n",
    "print(f'Dataset located in working dir: {DATASET_ZIP_PATH.is_file()}')\n",
    "\n",
    "## Parameters\n",
    "#PUNCTUATION_CHARS = {'(', ')', ':', ';', ',', '.', '\"', '»', '«', '[', ']', '{', '}', '%'}\n",
    "PUNCTUATION_CHARS = {char for char in string.punctuation}\n",
    "print(f'Set of punctuation characters used:\\n{PUNCTUATION_CHARS}')\n",
    "\n",
    "PRETRAINED_MODEL_NAME = 'rubert-base-cased'\n",
    "PRETRAINED_MODEL_OWNER = 'DeepPavlov'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "8cphdxx16vtid260etxy7r"
   },
   "outputs": [],
   "source": [
    "# Stage 0: Dataset loading and preprocessing\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"Our custom spin on the NLTK tokenizator\n",
    "    \n",
    "    NLTK wordpunct_tokenize(..) may return consequetive punctuation chars\n",
    "    as a single token. We want to overwrite this behavior and have each as\n",
    "    a separate token. Therefore validation and token list expantion is needed.\n",
    "    \"\"\"\n",
    "    def _is_punctuation_only(token: str) -> bool:\n",
    "        \"\"\"Simple check if the token string consist of punctuation only\n",
    "        \n",
    "        This is not very elegant but rather efficient way to do this.\n",
    "        First - build-in convertion of a string to set, which will leave\n",
    "        only unique characters. Then simply checking with its method\n",
    "        if the resulted set is a subset of our defined PUNCTUATION_CHARS.\n",
    "        \"\"\"\n",
    "        return True if set(token).issubset(PUNCTUATION_CHARS) else False\n",
    "\n",
    "    tokens = wordpunct_tokenize(text)       # Obtaining tokens via NLTK\n",
    "    validated_tokens = []\n",
    "    for token in tokens:\n",
    "        if _is_punctuation_only(token):\n",
    "            validated_tokens.extend(list(token))\n",
    "        else:\n",
    "            validated_tokens.append(token)\n",
    "    return validated_tokens\n",
    "\n",
    "\n",
    "def csv_tokens_from_txt(filepath: Path):\n",
    "    \"\"\"Read whole text file in a single string, tokenize and save as csv\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as txtfile:\n",
    "        # Easier way to read whole file in a long single-line string\n",
    "        text = txtfile.read().replace('\\n', ' ')\n",
    "    # Pandas dataframe directly from the list returned by function\n",
    "    data = pd.DataFrame(tokenize(text), columns=['token'])\n",
    "    filename = f'{filepath.stem}.csv'\n",
    "    data.to_csv(filepath.parent.joinpath(filename), index_label='id')\n",
    "\n",
    "\n",
    "def parse_tokens(dataset_root: Path):\n",
    "    \"\"\"Parse tokens from subfolders of dataset root (text.txt -> text.csv)\n",
    "    \"\"\"\n",
    "    for dirpath in tqdm(dataset_root.iterdir(), desc='Tokenization:'):\n",
    "        if not dirpath.is_dir() or not dirpath.joinpath('text.txt').exists():\n",
    "            continue        # Skip to the next iteration if not a subfolder\n",
    "        csv_tokens_from_txt(dirpath.joinpath('text.txt'))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellId": "tcwad4qwn9o6qsjlz2c24q",
    "id": "t1qHzCMTqnRO"
   },
   "outputs": [],
   "source": [
    "# Stage 1: Obtaining pretrained model\n",
    "from transformers import BertConfig, TFBertForTokenClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_model():\n",
    "    config = BertConfig.from_pretrained(\n",
    "                PRETRAINED_MODEL_NAME, \n",
    "                from_pt = True, num_labels=3)  \n",
    "    model = TFBertForTokenClassification.from_pretrained(\n",
    "                f'{PRETRAINED_MODEL_OWNER}/{PRETRAINED_MODEL_NAME}',\n",
    "                from_pt = True, config=config)\n",
    "    model.layers[-1].activation = tf.keras.activations.softmax\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "fvtql1xmt1uoawjrvfsmse"
   },
   "outputs": [],
   "source": [
    "################################## WORKFLOW ##################################\n",
    "# Stage 0.\n",
    "unpack_archive(DATASET_ZIP_PATH, INTERMID_DIR_PATH, 'zip')\n",
    "dataset_root = INTERMID_DIR_PATH.joinpath(DATASET_ZIP_PATH.stem)\n",
    "parse_tokens(dataset_root)\n",
    "# Stage 1.\n",
    "model = get_model()\n",
    "\n",
    "# Stage 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "qs9d84dg0vb05wn9hldg",
    "id": "RQPREaXJp8Z9"
   },
   "outputs": [],
   "source": [
    "def validate_sequence(seq: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "    \"\"\" Валидация последовательности тэгов: убеждаемся, что первый токен каждого термина имеет тэг \"B-TERM\"\n",
    "\n",
    "    :param seq: входная последовательность\n",
    "    :return: провалидированная последовательность\n",
    "    \"\"\"\n",
    "    is_previous_token = False\n",
    "    validated_seq = []\n",
    "    for token, tag in seq:\n",
    "        if tag == Tags.I_TERM.value:\n",
    "            if not is_previous_token:\n",
    "                validated_seq.append((token, Tags.B_TERM.value))\n",
    "            else:\n",
    "                validated_seq.append((token, tag))\n",
    "            is_previous_token = True\n",
    "        elif tag == Tags.B_TERM.value:\n",
    "            validated_seq.append((token, tag))\n",
    "            is_previous_token = True\n",
    "        else:\n",
    "            validated_seq.append((token, tag))\n",
    "            is_previous_token = False\n",
    "    return validated_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "l20wahdrgbauay708ueb5",
    "id": "Jabg8kB9di3P"
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Tags(Enum):\n",
    "    B_TERM = 'B-TERM'\n",
    "    I_TERM = 'I-TERM'\n",
    "    NOT_TERM = 'O'\n",
    "\n",
    "\n",
    "TERM_SET = {Tags.B_TERM.value, Tags.I_TERM.value}\n",
    "\n",
    "label2class = {\n",
    "            Tags.NOT_TERM.value: 0,\n",
    "            Tags.B_TERM.value: 1,\n",
    "            Tags.I_TERM.value: 2\n",
    "        }\n",
    "\n",
    "class2label = {\n",
    "            0: Tags.NOT_TERM.value,\n",
    "            1: Tags.B_TERM.value,\n",
    "            2: Tags.I_TERM.value\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ks90ebcsynipis2ag6byjo",
    "id": "tgMYA_XtsLm9"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "class Vectorizer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\",\n",
    "                                                        do_lower_case=False)\n",
    "\n",
    "        self._label2class = label2class\n",
    "        self._max_length = 134\n",
    "\n",
    "    def vectorize(self, text: List[str], token_labels: List[str]) -> Tuple[List[str], List[int], List[int], List[int]]:\n",
    "        tokenized_text, input_masks, labels = self._tokenize(text, token_labels)\n",
    "\n",
    "        input_ids = self._tokenizer.convert_tokens_to_ids(tokenized_text) # Преобразует последовательность токенов в последовательность идентификаторов, используя словарь.\n",
    "\n",
    "        tags = []\n",
    "        for label in labels:\n",
    "            tags.append(self._label2class[label])\n",
    "\n",
    "        input_ids = self._pad(input_ids)\n",
    "        input_masks = self._pad(input_masks)\n",
    "        tags = self._pad(tags)\n",
    "\n",
    "        return tokenized_text, input_ids, input_masks, tags\n",
    "\n",
    "    def _pad(self, input: List[Any]) -> List[Any]:\n",
    "        if len(input) >= self._max_length:\n",
    "            print(len(input))\n",
    "            return input[:self._max_length]\n",
    "        while len(input) < self._max_length:\n",
    "            input.append(0)\n",
    "        return input\n",
    "\n",
    "    def _tokenize(self, text: List[str], token_labels: List[str]) -> Tuple[List[str], List[int], List[str]]:\n",
    "        tokenized_text = []\n",
    "        labels = []\n",
    "\n",
    "        for token, label in zip(text, token_labels):\n",
    "            # Tokenize the word and count # of subwords the word is broken into\n",
    "            tokenized_word = self._tokenizer.tokenize(token)\n",
    "            n_subwords = len(tokenized_word)\n",
    "\n",
    "            # Add the tokenized word to the final tokenized word list\n",
    "            tokenized_text.extend(tokenized_word)\n",
    "\n",
    "            # Add the same label to the new list of labels `n_subwords` times\n",
    "            labels.extend([label] * n_subwords)\n",
    "\n",
    "        try:\n",
    "\n",
    "            inputs = self._tokenizer.encode_plus(\n",
    "                tokenized_text,\n",
    "                is_pretokenized=True,\n",
    "                return_attention_mask=True,\n",
    "                max_length=self._max_length,\n",
    "                truncation=True\n",
    "            )\n",
    "\n",
    "        except:\n",
    "            print(text)\n",
    "            inputs = dict()\n",
    "            inputs['attention_mask'] = np.zeros(self._max_length)\n",
    "\n",
    "        return tokenized_text, inputs['attention_mask'], labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "kxfgd41xx3do2uf1pckj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lB2cum1_s9f4",
    "outputId": "d87edd35-b7e0-4c9b-a91b-debbad74fd41"
   },
   "outputs": [],
   "source": [
    "%pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "gmnt6lfzxodjvwue15je5o",
    "id": "LB6sfi78s6Sq"
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from pymorphy2.analyzer import Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "02r3mc2b0p84k42ym3kplx",
    "id": "yHza_k7hstAH"
   },
   "outputs": [],
   "source": [
    "ADJF = 'ADJF'\n",
    "CONJ = 'CONJ'\n",
    "GRND = 'GRND'\n",
    "NOUN = 'NOUN'\n",
    "PREP = 'PREP'\n",
    "PRTF = 'PRTF'\n",
    "PRTS = 'PRTS'\n",
    "VERB = 'VERB'\n",
    "\n",
    "GENT = 'gent'\n",
    "\n",
    "\n",
    "class HeuristicValidator:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    def validate(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        result = self._heuristic_1(result)\n",
    "        result = self._heuristic_2(result)\n",
    "        result = self._heuristic_3(result)\n",
    "        result = self._heuristic_4(result)\n",
    "        result = self._heuristic_5(result)\n",
    "        result = self._heuristic_6(result)\n",
    "        result = self._heuristic_7(result)\n",
    "        # result = self._heuristic_8(result)\n",
    "        result = self._heuristic_9(result)\n",
    "        result = self._heuristic_10(result)\n",
    "        return result\n",
    "\n",
    "    def _heuristic_1(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Валидация цепочек, которые представляют собой СУЩ + СУЩ в род.п., например: методы сжатия данных\"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "        updated_tokens = set()\n",
    "\n",
    "        for i, (result_pair_1, result_pair_2) in enumerate(zip(result, result[1:])):\n",
    "            id_1 = i\n",
    "            id_2 = i + 1\n",
    "            # если последовательность не содержит терминов, то пропускаем\n",
    "            if result_pair_1[1] == Tags.NOT_TERM.value and result_pair_2[1] == Tags.NOT_TERM.value:\n",
    "                continue\n",
    "            token_1, token_2 = result_pair_1[0], result_pair_2[0]\n",
    "            pos_1 = self._morph.parse(token_1)[0].tag.POS\n",
    "            case_2 = self._morph.parse(token_2)[0].tag.case\n",
    "            if pos_1 in [NOUN, ADJF] and case_2 == GENT:\n",
    "                if result_pair_1[1] not in TERM_SET and id_1 not in updated_tokens:\n",
    "                    result_pair_1 = (token_1, Tags.B_TERM.value)\n",
    "                    updated_result[id_1] = result_pair_1\n",
    "                    updated_tokens.add(id_1)\n",
    "                result_pair_2 = (token_2, Tags.I_TERM.value)\n",
    "                updated_result[id_2] = result_pair_2\n",
    "                updated_tokens.add(id_2)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_2(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        Если токены представляют собой последовательность ПРИЛ + СУЩ и оба помечены B-TERM, то приводим к\n",
    "        последовательности B-TERM I-TERM\n",
    "        \"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, (result_pair_1, result_pair_2) in enumerate(zip(result, result[1:])):\n",
    "            id_1 = i\n",
    "            id_2 = id_1 + 1\n",
    "            # если последовательность не содержит терминов, то пропускаем\n",
    "            if result_pair_1[1] == Tags.B_TERM.value and result_pair_2[1] == Tags.B_TERM.value:\n",
    "                token_1, token_2 = result_pair_1[0], result_pair_2[0]\n",
    "                parse_1 = self._morph.parse(token_1)\n",
    "                parse_2 = self._morph.parse(token_2)\n",
    "                is_adj_1 = self.__check_pos(ADJF, parse_1)\n",
    "                is_noun_2 = self.__check_pos(NOUN, parse_2)\n",
    "                if is_adj_1 and is_noun_2:\n",
    "                    updated_result[id_1] = (token_1, Tags.B_TERM.value)\n",
    "                    updated_result[id_2] = (token_2, Tags.I_TERM.value)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_3(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Удаление тэга B-TERM или I-TERM, если он был присовен токену знака пунктуации \"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, result_pair in enumerate(result):\n",
    "            if result_pair[0] in ['.', ',', ':', ';'] and result_pair[1] in [Tags.B_TERM.value, Tags.I_TERM.value]:\n",
    "                updated_result[i] = (result_pair[0], Tags.NOT_TERM.value)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_4(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Если последний токен в термине имеет часть речи ПРИЛ, а следующий токен - СУЩ, но либо не входит в термин,\n",
    "        либо имеет тэг \"B-TERM\", то второй токен включаем в состав термина\n",
    "        \"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, (result_pair_1, result_pair_2) in enumerate(zip(result, result[1:])):\n",
    "            id_1 = i\n",
    "            id_2 = id_1 + 1\n",
    "            if result_pair_1[1] in TERM_SET and result_pair_2[1] != Tags.I_TERM.value:\n",
    "                token_1, token_2 = result_pair_1[0], result_pair_2[0]\n",
    "                parse_1 = self._morph.parse(token_1)\n",
    "                parse_2 = self._morph.parse(token_2)\n",
    "                is_adj_1 = self.__check_pos(ADJF, parse_1)\n",
    "                is_prtf_1 = self.__check_pos(PRTF, parse_1)\n",
    "                is_noun_2 = self.__check_pos(NOUN, parse_2)\n",
    "                if is_noun_2:\n",
    "                    if is_adj_1 or is_prtf_1:\n",
    "                        updated_result[id_2] = (token_2, Tags.I_TERM.value)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_5(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Удаление тэга B-TERM у предлога и союза (допускаем, что предлог может входить в состав термина, но не может\n",
    "        начинать его \"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, result_pair in enumerate(result):\n",
    "            if result_pair[1] == Tags.B_TERM.value:\n",
    "                parse = self._morph.parse(result_pair[0])\n",
    "                is_prep = self.__check_pos(PREP, parse)\n",
    "                is_conj = self.__check_pos(CONJ, parse)\n",
    "                if is_prep or is_conj:\n",
    "                    updated_result[i] = (result_pair[0], Tags.NOT_TERM.value)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_6(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Удаление тэга Термин у однозначного глагола или деепричастия \"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, result_pair in enumerate(result):\n",
    "            if result_pair[1] in [Tags.B_TERM.value, Tags.I_TERM.value]:\n",
    "                parse = self._morph.parse(result_pair[0])\n",
    "                is_verb = self.__check_pos(VERB, parse)\n",
    "                is_grnd = self.__check_pos(GRND, parse)\n",
    "                is_prts = self.__check_pos(PRTS, parse)\n",
    "                if len(parse) == 1:\n",
    "                    if is_verb or is_grnd or is_prts:\n",
    "                        updated_result[i] = (result_pair[0], Tags.NOT_TERM.value)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_7(self, result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Если следующий за термином токен состоит только из латинских символов, то включаем его в состав термина \"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, (result_pair_1, result_pair_2) in enumerate(zip(result, result[1:])):\n",
    "            id_1 = i\n",
    "            id_2 = id_1 + 1\n",
    "            if result_pair_1[1] in TERM_SET:\n",
    "                token_2 = result_pair_2[0]\n",
    "                is_latin = self._is_latin(token_2)\n",
    "                if is_latin:\n",
    "                    updated_result[id_2] = (token_2, Tags.I_TERM.value)\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_8(self, result: List[Tuple[str, str]]):\n",
    "        \"\"\" Удаление тэга B-TERM у предлога и союза, которые идут после определения\n",
    "        Н/р: ..исследование статистического и динамического провисания ..\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _heuristic_9(self, result: List[Tuple[str, str]]):\n",
    "        \"\"\"Чаще всего, всё, что стоит в кавычках, относится к термину, если он там выделен\n",
    "        Н/р: .. компьютерный инструмент «оптимизация с ограничениями» ..\"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, result_pair in enumerate(result):\n",
    "            if result_pair[0] in ['\"', '«', '“', 'ˮ']:\n",
    "                try:\n",
    "                    if result[i + 1][1] == Tags.B_TERM.value:\n",
    "                        is_fin = False\n",
    "                        k = 2\n",
    "                        while not is_fin:\n",
    "                            next_pair = result[i + k]\n",
    "                            is_fin = next_pair[0] in ['\"', '»', '”', '‟']\n",
    "                            if next_pair[1] not in TERM_SET and not is_fin:\n",
    "                                updated_result[i + k] = (next_pair[0], Tags.I_TERM.value)\n",
    "                            k += 1\n",
    "                except IndexError:  # если кавычки стоят в конце текста\n",
    "                    pass\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _heuristic_10(self, result: List[Tuple[str, str]]):\n",
    "        \"\"\"Исправление разметки терминов, которые пишутся через дефис.\n",
    "        Иногда часть составного термина при разметке \"теряется\"\n",
    "        Н/р: ... курсов математической физики, физико-математической информатики и дифференциальных уравнений ...\"\"\"\n",
    "\n",
    "        updated_result = {i: res for i, res in enumerate(result)}\n",
    "\n",
    "        for i, result_pair in enumerate(result):\n",
    "          try:\n",
    "            if result_pair[0] == \"-\" and ((result[i+1][1] in TERM_SET) ^ (result[i-1][1] in TERM_SET)):\n",
    "                if str(result[i-1][0])[-1] in ['о', 'е']:\n",
    "                    if result[i-1][1] not in TERM_SET:\n",
    "                        updated_result[i-1] = (result[i-1][0], Tags.B_TERM.value)\n",
    "                    updated_result[i] = (result[i][0], Tags.I_TERM.value)\n",
    "                    updated_result[i + 1] = (result[i + 1][0], Tags.I_TERM.value)\n",
    "          except IndexError:\n",
    "            pass\n",
    "\n",
    "        res = [updated_result[i] for i in range(len(result))]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def __check_pos(self, pos: str, parses: List[Parse]) -> bool:\n",
    "            for parse in parses:\n",
    "                if pos in parse.tag:\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "    def _is_latin(self, token: str) -> bool:\n",
    "        latin_symbols = 'qwertyuiopasdfghjklzxcvbnm'\n",
    "        is_latin = True\n",
    "        for char in token.lower():\n",
    "            if char not in latin_symbols:\n",
    "                is_latin = False\n",
    "                return is_latin\n",
    "        return is_latin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3yywpmh1zn71ud5yobgcz8",
    "execution_id": "e9b90a9d-4715-4ea6-865c-9fc7c742a153",
    "id": "nqksozIjtXBm"
   },
   "source": [
    "### DLExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "uv7lg2zgigl4cqb963rm5c",
    "id": "koAMWhKJtb-Y"
   },
   "outputs": [],
   "source": [
    "class DLExtractor(BaseExtractor):\n",
    "    \"\"\" Класс для извлечения терминов из текста с помощью модели \"\"\"\n",
    "\n",
    "    def __init__(self, weights_path):\n",
    "        weights_path = weights_path\n",
    "        self._model = get_model()\n",
    "        self._model.load_weights(weights_path)\n",
    "        self._vectorizer = Vectorizer()\n",
    "        self._heuristic_validator = HeuristicValidator()\n",
    "        self._class2label = class2label\n",
    "\n",
    "    def extract(self, text: Union[str, List[str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Извлечение терминов из входного текста\n",
    "\n",
    "        :param text: входной текст, может быть строкой либо уже токенизированным (тогда списком строк)\n",
    "        :return: Список кортежей, в которых первый элемент - токен, второй элемент - тэг\n",
    "        \"\"\"\n",
    "        if isinstance(text, str): # проверка на то, что далее работаем со списком строк (токенов)\n",
    "            tokens = tokenize(text)\n",
    "        else:\n",
    "            tokens = text\n",
    "\n",
    "        labels = [Tags.NOT_TERM.value for i in range(len(tokens))]\n",
    "\n",
    "        all_bpe_tokens = []\n",
    "        all_predictions = []\n",
    "\n",
    "        # делим список токенов на батчи, которые будут последовательно обрабатываться\n",
    "        n_batches = int(len(tokens) / 50) + 1\n",
    "        for i in range(n_batches):\n",
    "            start = 50 * i\n",
    "            end = min(len(tokens), 50 * i + 50)\n",
    "\n",
    "            if start == end:\n",
    "                break\n",
    "\n",
    "            bpe_tokens, input_ids, input_masks, tags = self._vectorizer.vectorize(\n",
    "                  tokens[start: end], labels[start: end]\n",
    "              )\n",
    "            preds = self._model.predict_on_batch([np.array([input_ids]), np.array([input_masks])])[0][0]\n",
    "            all_bpe_tokens.extend(bpe_tokens)\n",
    "            all_predictions.extend(preds[:len(bpe_tokens)])\n",
    "\n",
    "        result = self._get_preds_with_tokens(all_bpe_tokens, all_predictions)\n",
    "        result = self._heuristic_validator.validate(result)\n",
    "        result = validate_sequence(result)\n",
    "\n",
    "        if isinstance(text, list):\n",
    "            result = self._align_tokens(text, result)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _align_tokens(self, input_tokens: List[str], result: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Выравнивание токенов\n",
    "        В случаях, когда на вход пришёл уже токенизированный текст, токены в результирующем списке могут отличаться от\n",
    "        тех, что в исходном из-за bpe-токенизации. Поэтому нужно выровнить результирующий список относительно входного,\n",
    "        т.е. список токенов в обоих списках должен совпадать\n",
    "\n",
    "        :param input_tokens: список токенов во входном списке\n",
    "        :param result: результирующий список кортежей, в которых первый элемент - токен, второй - тэг\n",
    "        :return: список кортежей, в которых первый элемент - токен, второй - тэг\n",
    "        \"\"\"\n",
    "        # если списки токенов изначально совпадают, то сразу возвращаем результат\n",
    "        resulted_tokens = [res[0] for res in result]\n",
    "        if resulted_tokens == input_tokens:\n",
    "            return result\n",
    "\n",
    "        updated_result = []\n",
    "\n",
    "        # фиксируем позицию токена в результирующем списке\n",
    "        res_cursor = 0\n",
    "        for i, token in enumerate(input_tokens):\n",
    "\n",
    "            # токенизируем токен из входного списка. Если длина получившихся токенов == 1, то это не составной токен\n",
    "            tokenized = tokenize(token)\n",
    "            if len(tokenized) == 1: # если bpe-токен воспринимается как одно слово, добавляем его в результирующий список\n",
    "              try:\n",
    "                updated_result.append(result[i]) # result может быть длиннее, чем input_tokens\n",
    "                res_cursor += 1\n",
    "                continue\n",
    "              except:\n",
    "                print('here:', len(result))\n",
    "\n",
    "            full_resulted = []\n",
    "            tags = Counter()\n",
    "            # собираем все токены в результирующем списке, которые лежат в промежутке от res_cursor до\n",
    "            # res_cursor + количество токенов в tokenized\n",
    "            for j in range(res_cursor, res_cursor + len(tokenized)):\n",
    "                full_resulted.append(result[j][0])\n",
    "                tags[result[j][1]] += 1\n",
    "\n",
    "            # на случай, если составным токенам были присвоены разные тэги, то выберем тэг с максимальной частотой\n",
    "            tag = tags.most_common()[0][0]\n",
    "            updated_result.append((''.join(full_resulted), tag))\n",
    "\n",
    "            # переведём позицию курсора на количество составных частей исходного токена\n",
    "            res_cursor += len(tokenized)\n",
    "\n",
    "        assert len(input_tokens) == len(updated_result), 'Alignment worked incorrect'\n",
    "\n",
    "        return updated_result\n",
    "\n",
    "    def _get_preds_with_tokens(self, bpe_tokens: List[str], preds) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Из предсказаний для bpe-токенов получаем предскания для целых токенов\n",
    "\n",
    "        :param bpe_tokens: список bpe-токенов\n",
    "        :param preds: список предиктов от модели\n",
    "        :return: Список кортежей, в которых первый элемент - полноценный токен, второй элемент - тэг\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        token = []\n",
    "        tags = []\n",
    "\n",
    "        for bpe_token, pred in zip(bpe_tokens, preds):\n",
    "\n",
    "            # если bpe-токен не является началом целого токена, то он начинается с \"##\"\n",
    "            if bpe_token.startswith('##'):\n",
    "                token.append(bpe_token[2:])\n",
    "                tags.append(self._class2label[np.argmax(pred)])\n",
    "\n",
    "            else:\n",
    "                # если уже собрали токен до этого, то обработаем его и положим в результирущий список\n",
    "                if len(token) > 0:\n",
    "                    self._process_token(result, tags, token)\n",
    "\n",
    "                token = [bpe_token]\n",
    "                tags = [self._class2label[np.argmax(pred)]]\n",
    "\n",
    "        # обработаем последний токен и положим его в результирующий список\n",
    "        self._process_token(result, tags, token)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _process_token(self, result: List[Tuple[str, str]], tags: List[str], token: List[str]):\n",
    "        \"\"\"Обработка токена: собираем его из bpe-токенов, выбираем нужный тэг\n",
    "\n",
    "        :param result: результирующий список с токенами и тэгами\n",
    "        :param tags: список тэгов, который был получен для составных bpe-токенов\n",
    "        :param token: список bpe-токенов для данного токена\n",
    "        \"\"\"\n",
    "        # объединяем составные bpe-токены в единую строку\n",
    "        token_str = ''.join(token)\n",
    "\n",
    "        tag = Tags.NOT_TERM.value\n",
    "\n",
    "        # если во входном списке тэгов есть B-TERM или I-TERM, то выбираем данный тэг\n",
    "        if Tags.B_TERM.value in tags:\n",
    "            tag = Tags.B_TERM.value\n",
    "        elif Tags.I_TERM.value in tags:\n",
    "            tag = Tags.I_TERM.value\n",
    "\n",
    "        result.append((token_str, tag))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "w27xx3ncboapvk1hwby6",
    "execution_id": "bb06fd06-cbc6-4112-b2da-2a649ed3ea88",
    "id": "B3H9NHN4Itum"
   },
   "source": [
    "## get new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ffjtft0dd1oklw5o5agt2n",
    "id": "NSXQeLywTFR4"
   },
   "outputs": [],
   "source": [
    "class Marker:\n",
    "\n",
    "    def __init__(self, path_to_weights, path_to_files):\n",
    "        self._predictor = DLExtractor(path_to_weights)\n",
    "        self._path_to_files = path_to_files\n",
    "        self._max_len = 128\n",
    "\n",
    "    def mark_dataset(self):\n",
    "        c = 0\n",
    "        dirs = sorted(os.listdir(self._path_to_files))\n",
    "        path = self._path_to_files\n",
    "        for article_dir in tqdm(dirs, desc='loading dataset'):\n",
    "            if 'text.csv' in os.listdir(os.path.join(self._path_to_files, article_dir)):\n",
    "                filename = os.path.join(self._path_to_files, article_dir, 'text.csv')\n",
    "                df = pd.read_csv(filename)\n",
    "                with open(filename, 'r') as f:\n",
    "                    tokens = []\n",
    "                    labels = []\n",
    "                    file_samples = []\n",
    "                    file_labels = []\n",
    "                    reader = csv.DictReader(f)\n",
    "                    for row in reader:\n",
    "                        tokens.append(row['token'])\n",
    "                        if len(tokens) == self._max_len:\n",
    "                            file_samples.append(tokens)\n",
    "                            preds = self._predictor.extract(tokens)\n",
    "                            for (tok, tag) in preds:\n",
    "                                labels.append(tag)\n",
    "                            file_labels.append(labels)\n",
    "                            tokens = []\n",
    "                            labels = []\n",
    "                    if len(tokens) > 0:\n",
    "                        file_samples.append(tokens)\n",
    "                        preds = self._predictor.extract(tokens)\n",
    "                        for (tok, tag) in preds:\n",
    "                            labels.append(tag)\n",
    "                        file_labels.append(labels)\n",
    "                        try:\n",
    "                            df['tag'] = self.flatten_list(file_labels)\n",
    "                        except:\n",
    "                            print(file_labels)\n",
    "                    df.to_csv(filename[:-4]+'_labeled.csv', index=False)\n",
    "                c += 1\n",
    "        if c == len(dirs)-1:\n",
    "            print(f'{c} files marked up!')\n",
    "\n",
    "    def flatten_list(self, lists):\n",
    "      flat_list = []\n",
    "      for l in lists:\n",
    "          if type(l) is list:\n",
    "              for item in l:\n",
    "                  flat_list.append(item)\n",
    "          else:\n",
    "              flat_list.append(l)\n",
    "      return flat_list\n",
    "\n",
    "\n",
    "    def replace_space(self, y):\n",
    "      for elem in y:\n",
    "        if isinstance(elem, str):\n",
    "          for i in range(len(y)):\n",
    "            if y[i] == '':\n",
    "              y[i] = 'O'\n",
    "        elif isinstance(elem, list):\n",
    "          for sample in y:\n",
    "            for i in range(len(sample)):\n",
    "              if sample[i] == '':\n",
    "                sample[i] = 'O'\n",
    "      return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "fhf58yfjv4wc7yd6w4i519",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "um1KdfVYXuWR",
    "outputId": "7b30592d-3c5f-40f2-df73-ab18d921cfba"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    path_to_weights, path_to_files = 'weights/RUbert_cross_domain_main_weights.h5', 'Articles_dataset_rus'\n",
    "    marker = Marker(path_to_weights, path_to_files)\n",
    "    marker.mark_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "rj7ns22f8qel7az428ptz"
   },
   "source": [
    "*Note: Refactored styling mostly oriented on PEP8 with some custom addition to formatting from https://github.com/abramsci/seismology/blob/toolkit/toolkit/template.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "810oar01eetq73j1gal2mj",
    "execution_id": "203a1ce4-4e3d-4fc1-921a-3e24f4bfe287"
   },
   "source": [
    "**Workflow in a nutshell:**\n",
    "\n",
    "0. Dataset loading and preprocessing\n",
    "\n",
    "    0. Unzip the file located at DATASET_ZIP_PATH into INTERMID_DIR_PATH\n",
    "    1. Iterate via \n",
    "    2. Validate tokens\n",
    "\n",
    "1. Pretrained model loading and configuring\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-9JaZrB-eVus",
    "W2ngs-mSecGs",
    "O7T06d9FcdUz",
    "vP-vFHbQcgh7",
    "6TKkn7X5snzQ",
    "wQaEs5qTWevC",
    "saOCVa7JVUZ2"
   ],
   "provenance": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "022d162f-8569-450e-9801-a03561126262",
  "notebookPath": "preparation.ipynb",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0486752f1c244a8ea1d63730905e6138": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14b28b39580b4ac9908a35a9aa57efec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c03075efd2749d1b70e13bdf4cc1d76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5567e1d25fa4937b2149d3593510c55",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14b28b39580b4ac9908a35a9aa57efec",
      "value": 29
     }
    },
    "23ece7fef01f40dcb4eec2103e899652": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3289058bdf144a23bc29d53f7d56e25d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33756245041e4434a30cb82cd3642bdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a804cbf74bc34cc78696450965971f22",
       "IPY_MODEL_8cf6f946c797446ebeb5387954d07543",
       "IPY_MODEL_44f74acf14454c3da878e1d7a71c5a50"
      ],
      "layout": "IPY_MODEL_91d7725865974b28b496fda4233aad87"
     }
    },
    "35bdb5de9dc04549b4397a5a5ef72c55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39b1bd3ed29e4ddf8b7c29fa00762b4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3a49f0b63b4540aa98fccaf877bfd36f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c995af3ee4f41cabc2641d28ec017e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44f74acf14454c3da878e1d7a71c5a50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_925aaf7d90df43868d8b79221b28efcd",
      "placeholder": "​",
      "style": "IPY_MODEL_69a53c80d3e74b6a9a177310964a85fc",
      "value": " 996k/996k [00:00&lt;00:00, 3.89MB/s]"
     }
    },
    "510b4e1e218444e78947289b0447cc04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b96888e692dd4c4da4d9f0d979a58b83",
      "placeholder": "​",
      "style": "IPY_MODEL_640b2361f5cc4b578a6dfa983c18652c",
      "value": " 29.0/29.0 [00:00&lt;00:00, 625B/s]"
     }
    },
    "5b2a4b36806c4ecfabd2897a1e98d203": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c6080f11d9f4fa58a4ec78dbaaf42a0",
       "IPY_MODEL_99ab0115b4864288b289cb32cd875396",
       "IPY_MODEL_af422d81fbc841d797f6dfb606c79658"
      ],
      "layout": "IPY_MODEL_81621f9cd0754ce185f6904cca0c88ff"
     }
    },
    "5c1f5b6dc5594bb9ad5977adbe6b2533": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "640b2361f5cc4b578a6dfa983c18652c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69a53c80d3e74b6a9a177310964a85fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c6080f11d9f4fa58a4ec78dbaaf42a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a051be2a41974460b9ad233d5418a0d4",
      "placeholder": "​",
      "style": "IPY_MODEL_f5f354a6ac484a31a3b84c64f5b7e878",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "7e10bc0f10eb4f3a9754134c7f2b1cb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81621f9cd0754ce185f6904cca0c88ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cf6f946c797446ebeb5387954d07543": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c1f5b6dc5594bb9ad5977adbe6b2533",
      "max": 995526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_35bdb5de9dc04549b4397a5a5ef72c55",
      "value": 995526
     }
    },
    "91d7725865974b28b496fda4233aad87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "925aaf7d90df43868d8b79221b28efcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99ab0115b4864288b289cb32cd875396": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a54e8fa8f24848dcaef018e4792891af",
      "max": 625,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39b1bd3ed29e4ddf8b7c29fa00762b4f",
      "value": 625
     }
    },
    "a051be2a41974460b9ad233d5418a0d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a105d1b33ab24be8ad18d86a818400b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a54e8fa8f24848dcaef018e4792891af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a804cbf74bc34cc78696450965971f22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3289058bdf144a23bc29d53f7d56e25d",
      "placeholder": "​",
      "style": "IPY_MODEL_7e10bc0f10eb4f3a9754134c7f2b1cb0",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "af422d81fbc841d797f6dfb606c79658": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23ece7fef01f40dcb4eec2103e899652",
      "placeholder": "​",
      "style": "IPY_MODEL_0486752f1c244a8ea1d63730905e6138",
      "value": " 625/625 [00:00&lt;00:00, 22.7kB/s]"
     }
    },
    "b96888e692dd4c4da4d9f0d979a58b83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbba160310854ef0b5ad28b4a96a1c13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c48c6e99c5a8459d9bb94bd0ceec7bba",
       "IPY_MODEL_1c03075efd2749d1b70e13bdf4cc1d76",
       "IPY_MODEL_510b4e1e218444e78947289b0447cc04"
      ],
      "layout": "IPY_MODEL_3a49f0b63b4540aa98fccaf877bfd36f"
     }
    },
    "c48c6e99c5a8459d9bb94bd0ceec7bba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a105d1b33ab24be8ad18d86a818400b2",
      "placeholder": "​",
      "style": "IPY_MODEL_3c995af3ee4f41cabc2641d28ec017e0",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "f5567e1d25fa4937b2149d3593510c55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5f354a6ac484a31a3b84c64f5b7e878": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
